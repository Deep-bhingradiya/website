- day: 16
  month: Jun
  title: "Produktiver Workload mit OpenShift 4"
  subtitle: |
            <img src="/images/blogposts/Produktiver_Workload.png" alt="Produktiver Workload"/>
            Fast ein Jahr nach dem ersten Release von OpenShift 4 sind wir der Meinung, dass die OpenShift Container Platform (OCP) in der Version 4.4 bereit für produktiven Workload ist.     
  details: |
               <p>Unsere Erfahrungen haben gezeigt, dass es durchaus sinnvoll war, mit Upgrades - oder im Fall von OpenShift 4 mit Migrationen - zu warten, bis alle Kinderkrankheiten des neuen Major Releases behoben sind. Daher haben wir seit dem ersten Release 4.1 alle OpenShift Versionen auf Herz und Nieren getestet und den Reifegrad überprüft. Gleich zu Beginn haben wir einen <a href="https://appuio.ch/blog.html#2019-Aug-29">Blogpost</a> zu den wesentlichen Unterschieden zur 3er-Version geschrieben. Anschliessend haben VSHN und Puzzle, die Firmen hinter APPUiO, Erfahrungen mit den neuen Versionen gesammelt. So haben sich z.B. einige Engineers von VSHN eine Woche dediziert Zeit genommen und die neueste Version auf ihre <a href="https://www.appuio.ch/managed-private.html">Managed Plattform</a> geprüft. Bei Puzzle wurden Erfahrungen an der <a href="https://appuio.ch/blog.html#2020-Jan-30">mid-week</a> (eine "Projektwoche" des Middleware-Teams) gesammelt, wie bei <a href="https://www.appuio.ch/unmanaged.html">Self Managed Plattformen</a> der Kunde am besten unterstützt werden kann. Diese Erfahrungen haben wir auch an unserem letzten APPUiO BeerUp mit unserer Community geteilt.</p>
               <p><b>Vorteile eines Wechsels auf OpenShift 4</b></p>
               <p>Aus unserer Sicht bringt die neueste OpenShift Version viele Vorteile für den Betreiber als auch für den Anwender.</p>
               <p>Der Reifegrad der neu eingesetzten Operators lässt unterdessen kaum noch zu wünschen übrig. Für den Betrieb eines Clusters werden Updates einerseits wesentlich schneller und andererseits ungemein einfacher und stabiler. Auch der Betrieb wird so vereinfacht, da die Operators auf Veränderungen reagieren und diese bei Bedarf korrigieren können. Operators sind ein neues Konzept auch für den Betrieb von Applikationen als Anwender von OpenShift. Diese neue Welt benötigt natürlich eine Einarbeitungszeit bis sich auch das Debugging so einfach anfühlt wie bei Deployments bisher.</p>
               <p>Der Umstieg von Docker auf Buildah für Container Builds ermöglicht es nun, auf sicherere Art und Weise Container Images zu bauen. Dies ist für alle Multitenant-Cluster wie Public Plattform-Anbieter und firmeninterne Cluster mit mehreren Benutzern eine erfreuliche Neuerung. Mit der Einführung des OpenShift Service Mesh erhalten insbesondere Entwickler einen neuen Einblick und neue Möglichkeiten, die Kommunikation ihrer Applikationen zu visualisieren, abzusichern und zu optimieren.</p>
               <p>Eine Liste der <a href="https://docs.openshift.com/container-platform/4.4/release_notes/ocp-4-4-release-notes.html">neuesten Features</a> findet ihr hier.</p>
               <p><b>Self Managed</b></p>
               <p>Entscheidet sich der Kunde für unser Self Managed Produkt, helfen wir ihm beim Aufbau der Container Plattform, geben unser Know-How weiter und unterstützen beim Engineering sowie beim Automatisieren von Deployments (CI/CD).</p>
               <p>Dabei haben wir bereits verschiedene OpenShift 4.3 und 4.4 Plattformen aufgebaut, sei es bei einer Verwaltung in Basel oder einem Amt in Bern. Weiter haben wir erste Migrationen von OpenShift 3.11 auf 4.3 durchgeführt. Weil es keinen Upgrade-Pfad gibt, muss ein neuer Cluster aufgebaut und der Workload migriert werden. Dies konnten wir ebenfalls bereits bei verschiedenen Kunden umsetzen, z.B. bei der <a href="https://www.puzzle.ch/referenzen/openshift-plattform-fuer-die-bls-ag">BLS</a>.</p>
               <p><b>Managed</b></p>
               <p>Entscheidet sich der Kunde für unser Managed Produkt, übernehmen wir den Aufbau und zusätzlich den Betrieb der Container Plattform. Damit der Betrieb reibungslos und weithin automatisiert vonstattengeht, müssen verschiedenste Prozesse angepasst und automatisiert werden. Die Plattform muss zuerst akkurat getestet werden. Weil dies etwas Zeit in Anspruch nimmt, sieht die Roadmap für die Managed Cluster je nach Infrastruktur wie folgt aus:</p>
               <div style="padding-left: 30px;">▸ Google GCP Q2 2020</div>
               <div style="padding-left: 30px;">▸ cloudscale.ch Q3 2020</div>
               <div style="padding-left: 30px;">▸ Azure Q3 2020</div>
               <div style="padding-left: 30px;">▸ AWS Q3 2020</div>
               <div style="padding-left: 30px;">▸ Exoscale Q4 2020</div>
               <div style="padding-left: 30px;">▸ VMware Q4 2020</div>
               <div style="padding-left: 30px;">▸ Hyper-V Q4 2020</div>
               <p><b>Public</b></p>
               <p>Für unsere Public Cloud, welche abhängig von den automatisierten Abläufen und dem Testing des Managed Produkts ist, wird es im Q3 ein Beta-Programm geben. Gerne dürfen Kunden daran teilnehmen. Dabei erhältst du Early Access auf die OpenShift 4 Plattform und kannst deine Applikationen darauf testen. Falls du dich für OpenShift 4 interessierst, kannst du dich hier für das Early Access Programm anmelden.</p>
               <script>
               var isLocal = window.location.host.indexOf('local.') > -1
               var isQa = /hubspotqa|hsformsqa/.test(window.location.hostname)
               
               var embedScript = document.createElement('script')
               embedScript.type = 'text/javascript';
               embedScript.onreadystatechange = function () {
                 if (this.readyState == 'complete' || this.readyState == 'loaded') {
                   window.renderStandalone();
                 }
               }
               embedScript.onload = function() { window.renderStandalone(); }
               
               if(isLocal){
                 embedScript.src = '../FormsNext/static-3.510/bundles/project_for_test.js'
               }else if (isQa) {
                 embedScript.src = '//js.hsformsqa.net/forms/v2.js'
               } else {
                 embedScript.src = '//js.hsforms.net/forms/v2.js'
               }
               document.getElementsByTagName('head')[0].appendChild(embedScript);
               </script>
               <script type="text/javascript" async="" defer="" src="https://js.hs-scripts.com/7105834.js"></script>
               <p><b>Schulungen und Techlabs</b></p>
               <p>Natürlich läuft unser <a href="https://appuio.ch/blog.html#2020-Mar-18">APPUiO Techlab auch auf der neuen OpenShift Version</a>. Falls du an einem Nachmittag mehr über OpenShift 4 und Operators erfahren möchtest, darfst du dich gerne hier <a href="https://appuio.ch/techlabs.html">anmelden</a>. Ab dem Sommer werden wir ein weiteres Techlab durchführen, das <a href="https://appuio.ch/ammtechlab.html">Application Migration and Modernization (AMM) Techlab</a>. Es zeigt dir auf, wie du Applikationen deiner Systemlandschaft auf die neue Container Plattform bringst. Weiter sind unsere Schulungsunterlagen für die Operations und die Apps on OpenShift Schulung auf der neusten OpenShift Version.</p>
               <p>Brauchst du Unterstützung mit deiner Plattform oder möchtest gerne eine neue Plattform aufbauen? Melde dich bei uns und wir trinken gemeinsam einen Kaffee oder ein Bier (geht auch remote). Melde dich bei <a href="mailto:hello@appuio.ch">hello@appuio.ch</a>.</p>

- day: 28
  month: Mai
  title: "Das Amt für Informatik & Organisation und APPUiO"
  subtitle: |
            <img src="/images/blogposts/Self_Managed.png" alt="Kanton Solothurn"/>
            Die technologische Verantwortung liegt im Kanton Solothurn beim Amt für Informatik und Organisation (AIO). Das AIO ist die zentrale Anlaufstelle für alle Informatikbelangen und verantwortlich für die Umsetzung, Beratung und Unterstützung der Departemente sowie den Unterhalt und Betrieb der zentralen und/oder übergreifenden Informatik- und Kommunikationssystemen. Kanton Solothurn setzt beim Aufbau einer modernen Container-Plattform auf APPUiO. Mit der neuen PaaS unterstützt das AIO die Arbeit der kantonalen Verwaltung und deren Departemente. 
          
  details: |
               <p>Die Umgebung der klassischen IT vom AIO war bis zum Jahr 2017 für die Entwickler sehr komplex, zeitaufwändig, unflexibel und schwer zu koordinieren. Nach intensiver Recherche wurde der Einsatz von OpenShift als neue Plattform gewählt. Das Ziel dabei war es, einen effizienteren Betrieb und eine verbesserte Zusammenarbeit zwischen Entwicklung und Betrieb zu erlangen. Dabei wurde eine OpenShift Plattform von APPUiO aufgebaut. Weiter sammelten die System Engineers Erfahrungen mit der Plattform, damit der Betrieb einwandfrei funktioniert. Dies beinhaltet eine Integration ins Monitoring, Alerting und ein funktionierendes Backup.</p>
               <p>Aus dem vielfältigen Angebot von APPUiO entschied sich das Amt für Informatik und Organisation des Kanton Solothurn für die APPUiO <a href="https://appuio.ch/unmanaged.html">"Self Managed"</a>-Lösung: Eine Container Plattform im eigenen Rechenzentrum, optimal integriert in die eigene Infrastruktur.</p>
               <p>Von dem Architektur Workshop, wobei gemeinsam die Architektur der Plattform definiert wurde, bis hin zum Deployment und Konfiguration des Clusters wurde das AIO von unseren Experten unterstützt. Das Setup wurde gemeinsam umgesetzt, wodurch bereits das Know-How der Engineers des Kanton Solothurns aufgebaut werden konnte. Im Anschluss des Cluster Aufbaus profitierte das AIO vom OpenShift 3rd Level Support Angebot unserer Experten. Die Supportleistungen beziehen sich auf die Analyse und Lösung technischer Problemstellungen ihrer OpenShift Plattform. Zudem kann das AIO das Supportteam bei fachlichen und technischen Fragestellungen oder bei Cluster Upgrades konsultieren. Der Vorteil für das AIO sind die kompetenten Kenntnisse des Supportteams sowie die präferierten Reaktionszeiten. Dank dem 3rd Level Support konnte ein reibungsloser Betrieb von Beginn an ermöglicht werden.</p>

- day: 22
  month: Apr
  title: "Kostenloses Upgrade: Höhere Performance auf APPUiO Public"
  subtitle: |
            <img src="/images/blogposts/faster_is_better.png" alt="faster ist better"/>
            Fantastische Neuigkeiten für alle Nutzer von APPUiO Public Shared: Wir haben kürzlich erfolgreich unsere APPUiO Public-Infrastruktur auf ein ganz neues Niveau gehoben. Alle APPUiO Public Shared Nodes und Storage Nodes wurden auf die neuen <b>Plus</b>-Flavors auf <a href="https://www.cloudscale.ch/de/">cloudscale.ch</a> upgegraded. Das bedeutet, dass ihr bei gleichem Preis automatisch von einer höheren Geschwindigkeit und Leistung profitiert. Einige APPUiO-Kunden berichteten uns von einer Leistungssteigerung von rund 15% im Vergleich zur alten Infrastruktur. 
          
  details: |
             <p>Bei den neuen Plus-Flavors handelt es sich um hochleistungsfähige Cloud-Server auf der neuesten verfügbaren Hardware-Plattform, wobei die zugrundeliegende physische Rechenleistung nicht überbucht wird. Wir hoffen, dass ihr mit diesem Upgrade ebenso zufrieden sind wie wir und würden uns freuen, von euren Erfahrungen zu hören.</p>
             <p><b>APPUiO Public auf <a href="https://www.cloudscale.ch/de/">cloudscale.ch</a></b></p>
             <p><a href="https://www.cloudscale.ch/de/">cloudscale.ch</a> ist der APPUiO Infrastruktur-Partner seit Beginn von APPUiO. Dank ihrer brandneuen AMD-basierten Hardware-Plattform können Kunden von Hochleistungsumgebungen profitieren. So ist gewährleistet, dass die benötigte Rechenleistung jederzeit zur Verfügung steht. Ermöglicht wird dieses Angebot durch den Einsatz modernster Hardware. <a href="https://www.cloudscale.ch/de/">cloudscale.ch</a> ist einer der ersten IaaS-Anbieter überhaupt, der Compute-Nodes mit den kürzlich lancierten AMD EPYC "Rome"-Prozessoren mit bis zu 64 physikalischen Kernen pro Sockel einsetzt.</p>
             <p>Weitere Informationen findet ihr auf dem <a href="https://www.cloudscale.ch/de/news/2019/11/19/noch-mehr-power-dank-plus-flavor">cloudscale.ch Blog</a>.</p>


- day: 25
  month: Mar
  title: "Coronavirus: APPUiO 90 Tage kostenlos"
  subtitle: |
            <img src="/images/blogposts/Voucher_Corona.png" alt="Voucher APPUiO Public 4.3"/>
            Wir erleben gerade noch nie dagewesene Zeiten aufgrund des Coronavirus. Die COVID-19-Pandemie hat erhebliche Auswirkungen auf die Gesundheit der Menschen, unseren Alltag wie auch auf Unternehmen und die Wirtschaft. Angesichts dieser besonderen und immer grösser werdenden Herausforderungen, die wir alle momentan meistern müssen, möchten wir von APPUiO ebenfalls einen Beitrag leisten.
          
  details: |
             <p>Deshalb bieten wir dir als "Soforthilfe" ein APPUiO Public auf <a href="https://www.cloudscale.ch/de/">cloudscale.ch</a> mit 1100 mC CPU, 2.0 GiB Memory für volle 90 Tage kostenlos an, was einem Wert von CHF 300.- entspricht.</p>
             <p>Geh einfach auf <a href="https://register.appuio.ch/">https://register.appuio.ch/</a>, gib deine E-Mail-Adresse und den folgenden Voucher-Code ein: <b>APPUIO-COVID19</b></p>
             <p>Beeil dich, es sind maximal 100 Codes verfügbar und die Aktion gilt 1x pro Benutzer bzw. Firma.</p>
             <p>Liebe Grüsse und trage Sorge zu dir</p>
             <p>dein APPUiO-Team.</p>
             


- day: 18
  month: Mar
  title: "Neu: Techlab auf OpenShift 4.3"
  subtitle: |
            <img src="/images/blogposts/techlab_auf_openshift_4.3.png" alt="techlab auf OpenShift 4.3"/>
            Vor einiger Zeit hat Red Hat die OpenShift Version 4.3 auf den Markt gebracht. Diese Version hat eine gewisse Reife und kann mit gutem Gewissen auch für produktiven Workload verwendet werden. Aus diesem Grund bieten wir unsere Techlabs neu auf OpenShift 4.3 an!
          
  details: |
             <p>Wie es der Zufall so will, werden wir unsere #40 Durchführung unseres gratis APPUiO Techlabs auf Basis von OpenShift 4.3 durchführen. Dabei zeigen wir dir die Unterschiede zu der Version 3 und geben unsere Erfahrungen sowie Tipps und Tricks weiter. Du machst erste Schritte auf einer OpenShift 4.3 Plattform, deployst Applikationen und skalierst diese ganz einfach. Weiter haben wir ein Operator Lab erarbeitet, wo du erste Gehversuche mit dem neuen Operator Framework machen kannst.</p>
             <p>Melde dich wie gewohnt über unsere <a href="https://appuio.ch/techlabs.html">Webseite</a> an.</p>
             <p><b>Aus aktuellen Umständen werden wir die kommende Durchführung am 26. März 2020 Remote abhalten. Wenn du dich für das Techlab anmeldest, erhältst du einen Link für die Techlab Remote Session.</b></p>
             <p>Dies wird für alle Beteiligten eine interessante Erfahrung und wir sind gespannt auf diese neue Herausforderung.</p>
             <p>Falls du Fragen zur Migration von OpenShift 3.11 auf 4.3 hast, helfen wir dir gerne weiter oder schätzen wir gemeinsam den Aufwand einer solchen Migration. Meld dich dafür ganz einfach per <a href="mailto:hello@appuio.ch">Mail</a>.</p>
             <p>Wenn du dich bereits ein wenig über OpenShift 4 informieren willst, kannst du <a href="https://appuio.ch/blog.html#OpenShift%204">diesen Blogpost</a> lesen.</p>
             <p>Bleibt alle gesund und "häbet Sorg"!</p>

- day: 30
  month: Jan
  title: "Red Hat OpenShift 4.2 – Installations Pitfalls, Networking und Storage"
  subtitle: |
            <img src="/images/blogposts/OpenShift_4.2.png" alt="OpenShift 4.2"/>
            <br>
            <a href="https://www.puzzle.ch/de/home">Puzzle ITC</a>, einer der Gründerfirmen von APPUiO, hat eine Woche genutzt, um ihr Wissen rund um OpenShift 4.2 zu vertiefen. In der sogenannten  <a href="https://www.puzzle.ch/de/blog/articles/2020/01/15/mid-week">/mid Week</a> erzielten die Members spannende Erkenntnisse bei der Installation, Networking und Storage.</a>
  details: |
             <p>Der Blog ist aufgeteilt in drei Themen:</p>
             <p><b>1. Installations-Pitfalls:</b> In der /mid Week haben wir OpenShift 4.2 sowohl auf einem VMware vSphere Cluster wie auch bei AWS, GCP und Azure installiert. Wir berichten über die Probleme, die dabei aufgetaucht sind.</p>
             <p><b>2. Networking:</b> Je nach Cloud Plattform gibt es logischerweise Unterschiede (z.B. Load Balancer). Wir haben aber auch Unterschiede zwischen OpenShift 3.11 und 4.2 festgestellt.</p>
             <p><b>3. Storage:</b> Jeder Cloud Provider bietet diverse Typen von Storage zur Integration in OpenShift an. Wir zeigen euch, was es für Möglichkeiten gibt.</p>
             <b><u>1. Installation Pitfalls</u></b>
             <p><img src="/images/blogposts/Pitfalls.jpg" alt="Pitfalls"/></p>
             <p>Wenn du in diesem Blog nach einer Anleitung suchst, wie OpenShift 4.2 installiert wird, bist du leider falsch. Für die Installationen haben auch wir die offiziellen <a href="https://docs.openshift.com/container-platform/4.2/welcome/index.html">Anleitungen von Red Hat</a> verwendet.</p>
             <p>Vorneweg: Die Installation wird mit OpenShift Version 4.2 deutlich einfacher und schneller als mit 3.11. Generell - egal für welche Zielplattform - haben wir Folgendes festgestellt:</p>
             <li>Kleinere Umgebungen als 3 Master / 3 Node (Standardvorgabe) sollten nicht gewählt werden. Es wird sehr langsam oder die Installation schlägt teilweise sogar fehl. </li>
             <li>Für den OpenShift Installer wird ein <em>install-config.yaml</em> File erstellt. Dies sollte vor Beginn der Installation gesichert werden, da der Installer dieses anschliessend löscht.</li>
             <li>Weiter sollten auch alle Terraform Output Files gesichert werden, damit später der Cluster einfach gelöscht werden kann. Achtung, beim Löschen des Cluster erfolgt keine zusätzliche Bestätigung!</li>
             <li>Je nach Plattform haben wir unterschiedliche Grössen der Standard-VM festgestellt.</li>
             <li>Wenn <a href="https://docs.openshift.com/container-platform/4.2/installing/installing_aws/installing-aws-customizations.html#ssh-agent-using_install-customizations-cloud">während der Installation</a> kein SSH-Keyfile angegeben wurde, kann anschliessend nicht auf die VM's per SSH zugegriffen werden.</li>
             <p>Die Installation eines Clusters dauert je nach Plattform unterschiedlich lang:</p>
             <img src="/images/blogposts/Installationsdauer.png" alt="Installationsdauer"/>
             <p><b>VMware vSphere</b></p>
             <p>Einige Bemerkungen zur VMware vSphere Installation:</p>
             <li>Die Dokumentation zur Installation war sehr gut und wir konnten dieser Schritt für Schritt folgen.</li>
             <li>Während der (ersten) Installation mussten wir feststellen, dass Reverse DNS Einträge zwingend notwendig sind. Die Installation war blockiert und wir mussten von neuem beginnen.</li>
             <li>Kleine Fehler in den Ignition (JSON) Files führen zu Fehler, die leider sehr schwer zu finden sind, da keine sinnvolle Fehlermeldung vorhanden ist. So hat uns z.B. ein fehlendes Komma etwa eine Stunde Zeit gekostet. Ignition Files können <a href="https://coreos.com/validate/">hier</a> validiert werden.</li>
             <li>Für die Installation muss ein Load Balancer (z.B. HAproxy) erstellt werden. Siehe auch unten im Teil zu Networking.</li>
             <li>Infrastructur MachineSets für vSphere sind noch nicht implementiert. Daher ist die Installation auf VMware vSphere auch eine <a href="https://blog.openshift.com/openshift-4-install-experience/">User Provisioned Infrastructure (UPI)</a> Installation.</li>
             <p><b>GCP</b></p>
             <p>Damit die Installation auf GCP funktioniert, müssen die folgenden APIs aktiviert sein:</p>
             <li>Identity and Access Management(IAM)</li>
             <li>Cloud Resource Manager API</li>
             <p>Weiter muss die Disksize Limit von 500GB auf 750 GB erh&ouml;ht werden (640GB benutzt nach der Installation). Das Definieren im <em>install-config.yaml</em> File des OpenShift Installer funktioniert leider nicht:</p>
             <pre class="western">
             platform:
                gcp:
                   rootVolume:
                   iops: 4000
                   size: 50
                   type: io1
                type: n1-standard-4</pre>
             <p><b>Azure</b></p>
             <p>Einige Bemerkungen zur Installation auf Azure:</p>
             <li>Free Tier Subscription reicht nicht aus für eine OpenShift Installation.</li>
             <li>Es müssen Anpassungen an den default Azure Account Limits gemacht werden.</li>
             <li>Zürich befindet sich z.Z. nicht unter den supported Azure Regions.</li>
             <li>Die Dokumentation ist falsch bzgl. <em>Azure account limits & Creating a service principal</em>.</li>
             <p><b>AWS</b></p>
             <p>Die Installation auf AWS war am einfachsten. Das liegt wohl daran, dass bereits Openshift 4.0 darauf ausgelegt war.</p>
             <b><u>2. Networking</u></b>
             <p><img src="/images/blogposts/networking.png" alt="networking"/></p>
             <p><b>Load Balancing</b></p>
             <p>Für eine Red Hat OpenShift 4.2 Installation werden zwei Load Balancer vor dem Cluster benötigt:</p>
             <li><b>API Load Balancer:</b> Für eine Hochverfügbarkeit der Kubernetes-API (welche auf dem Master läuft), müssen alle API Calls an diese Master Nodes verteilt werden.</li>
             <p>Auf den drei Cloud Provider konnten wir dafür jeweils den Load Balancer Service des Providers verwenden. Dieser wird mit dem OpenShift Installer automatisch konfiguriert. Auf VMware vSphere mussten wir dafür selber einen Load Balancer konfigurieren. Wir haben dafür eine CentOS VM mit HAProxy verwendet. Für die hohe Verfügbarkeit kann z.B. keepalived verwendet werden.</p>
             <li><b>Client Access Load Balancer:</b> Für den Zugriff auf den Applikation Workload wird ein Load Balancer benötigt, der die Ingress Controller weiterleitet.</li>
             <p>Für den Client Access Load Balancer kann auf die Cloud Provider Integration von Kubernetes zurückgegriffen werden. Damit werden mit Hilfe eines <a href="https://kubernetes.io/docs/concepts/services-networking/service/#
             lancer">Kubernetes Services vom Typ Load Balancer</a> automatisch ein Load Balancer auf der entsprechenden Cloud Plattform provisioniert.</p>
             <p>Bei der on-premise Installation mit VMware vSphere muss der Load Balancer selber implementiert werden, welcher den Netzwork Traffic auf die Ingress Controller weiterleitet. Das automatische Erstellen des Load Balancers via Kubernetes Service funktioniert hier leider nicht.</p>
             <p><b>Egress Traffic & NetworkPolicy</b></p>
             <li><b>NetworkPolicy:</b>Die Kubernetes v1 NetworkPolicy Features sind in OpenShift 4.2 verfügbar</li>
             <li><b>Egress IP:</b> Identisch zu OpenShift 3.11. <a href="https://docs.openshift.com/container-platform/4.2/networking/openshift-sdn/assigning-egress-ips.html">(Referenz)</a></li>
             <li><b>EngressNetworkPolicy</b> wir auf OpenShift 4.2 nicht unterstützt </li>
             <li><b>EgressRouter</b> wird auf OpenShift 4.2 nicht unterstützt </li>
             <b><u>3. Storage</u></b>
             <p><img src="/images/blogposts/storage.jpg" alt="storage"/></p>
             <p>Abschliessend schauen wir uns noch die diversen Storage Integrationen für OpenShift 4.2 an. Wir teilen Storage in drei Kategorien ein: Block Storage, File Storage und Object Storage.</p>
             <p><b>Black Storage</b></p>
             <p>Erfreulicherweise hatten wir mit keinem Provider (onpremise wie auch Cloud) Probleme. Nach der Installation gemäss Anleitung konnten wir Block Storage von allen Cloud Providern beziehen. Alle Infos dazu sind in der entsprechenden Dokumentation von Red Hat zu finden.</p>
             <li><a href="https://docs.openshift.com/container-platform/4.2/storage/persistent-storage/persistent-storage-gce.html">GCP</a></li>
             <li><a href="https://docs.openshift.com/container-platform/4.2/storage/persistent-storage/persistent-storage-azure.html">Azure</a></li>
             <li><a href="https://docs.openshift.com/container-platform/4.2/storage/persistent-storage/persistent-storage-aws.html">AWS</a></li>
             <li><a href="https://docs.openshift.com/container-platform/4.2/storage/persistent-storage/persistent-storage-vsphere.html">vSphere</a></li>
             <p><b>File Storage</b></p>
             <p>Als File Storage bezeichnen wir solchen, der insbesondere shared bezogen werden kann <a href=https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes">(ReadWriteMany - RWX)</a>.</p>
             <p><b>AWS</b></p>
             <p>Auf AWS steht uns <a href="https://aws.amazon.com/efs/">EWS</a> zur Verfügung, dabei haben wir jedoch Folgendes festgestellt:</p>
             <li>Auf EFS sind alle Volumes nur Subfolder des Root Volume.</li>
             <li>Quotas können nicht forciert werden.</li>
             <li>Keine Usage Metrics</li>
             <li><em>size</em> in einem PVC wird nicht berücksichtigt.</li>
             <li>Red Hat sagt zu EFS: <em>"Elastic File System is a Technology Preview feature only.[...]"</em> <a href="https://docs.openshift.com/container-platform/4.2/storage/persistent-storage/persistent-storage-efs.html">Openshift doc on EFS</a></li>
             <li>upstream efs-provisioner: <a href="https://github.com/kubernetes-incubator/external-storage/tree/master/aws/efs">detailed doc & code</a></li>
             <p>Weiter kann auch Netapp Trident verwendet werden. In unserer /mid Week haben wir dies jedoch nicht angeschaut (auch nicht auf den anderen Cloud Provider Plattformen). Dafür wird ein AWS Account mit konfiguriertem NetApp CVS (1TB / 100$ / Monat) benötigt. Infos dazu in der <a href="https://netapp-trident.readthedocs.io/en/stable-v19.07/kubernetes/operations/tasks/backends/cvs_aws.html">Netapp Trident Dokumentation</a>.</p>
             <p><b>Azure</b></p>
             <p>Microsoft bietet mit Azure File die Möglichkeit, dynamisch File Storage zu beziehen. Die folgenden Features werden dabei aber nicht supported.</p>
             <li>Symlinks</li>
             <li>Hard links</li>
             <li>Extended attributes</li>
             <li>Sparse files</li>
             <li>Named pipes</li>
             <p>Alle Informationen dazu sind in der <a href="https://docs.openshift.com/container-platform/4.2/storage/dynamic-provisioning.html#azure-disk-definition_dynamic-provisioning">Red Hat OpenShift Dokumentation</a> zu finden. Auch auf Azure kann <a href="https://netapp-trident.readthedocs.io/en/stable-v19.07/kubernetes/operations/tasks/backends/anf.html">Netapp Trident</a> verwendet werden.</p>
             <p><b>GCP</b></p>
             <p>Auf GCP stehen <a href="https://cloud.google.com/solutions/filers-on-compute-engine">mehrere Möglichkeite</a>n zur Verfügung.</p>
             <p>Für <a href="https://cloud.google.com/community/tutorials/gke-filestore-dynamic-provisioning">Cloud File Store kann der nfs-client-provisioner</a> verwendet weren. Auch hier können Quotas nicht forciert werden. Weiter gibt es einen nicht offiziell supporteten <a href="https://github.com/kubernetes-sigs/gcp-filestore-csi-driver">CSI Treiber</a>, den wir aber nicht wirklich zum Laufen gebracht haben.</p>
             <p>Weiter kann auch hier NetApp Cloud Volumes mit Trident verwendet werden. Wir haben hierzu aber keine Dokumentation gefunden. Dies sollte aber ähnlich wie bei <a href="https://netapp-trident.readthedocs.io/en/stable-v19.04/kubernetes/operations/tasks/backends/cvs_aws.html">AWS</a> seine. Weitere Infos dazu sind <a href="https://cloud.google.com/solutions/filers-on-compute-engine#netapp">hier</a> zu finden.</p>
             <p>Eine weitere Möglichkeit ist die Verwendung von <a href="https://github.com/Elastifile/elastifile-provisioner">Elastifile</a> oder <a href="https://github.com/quobyte/quobyte-csi">Quoabyte</a>. Diese müssen aber alle lizenziert werden. Elastifile ist nur für einen eingeschränkten Kundenkreis verfügbar. Quoabyte sieht zur Zeit noch nicht wirklich Enterprise-like aus.</p>
             <p><b>VMware vSphere</b></p>
             <p>In einer on-premise VMware vSphere Umgebung muss einen File Storage Service selbst aufgebaut werden (z.B. mit <a href="https://www.openshift.com/products/container-storage/">Red Hat Contrainer Storage</a> basierend auf <a href="https://rook.io/">rook.io</a>).</p>
             <p><b>Object Storage</b></p>
             <p>Auch Object Storage wird von den drei Cloud Provider angeboten. Dieser wird aber in der Regeln nicht als PV in einen Pod gemounted, sondern direkt aus einer Applikation bezogen. Der Vollständigkeit halber hier eine Auflistung der Object Storage Services.</p>
             <li>GCP mit <a href="https://cloud.google.com/storage/">Google Cloud Storage</a></li>
             <li>AWS mit <a href="https://aws.amazon.com/s3/">S3</a></li>
             <li>Azure mit <a href="https://azure.microsoft.com/en-us/services/storage/">Azure Object Storage</a></li>
             <p>In einer on-premise VMware vSphere Umgebung muss ein Object Storage Service selbst aufgebaut werden.</p>
