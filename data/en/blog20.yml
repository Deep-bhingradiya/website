- day: 28
  month: Mai
  title: "Das Amt für Informatik & Organisation und APPUiO"
  subtitle: |
            <img src="/images/blogposts/Unmanaged_AIO.png" alt="Kanton Solothurn"/>
            Die technologische Verantwortung liegt im Kanton Solothurn beim Amt für Informatik und Organisation (AIO). Das AIO ist die zentrale Anlaufstelle für alle Informatikbelangen und verantwortlich für die Umsetzung, Beratung und Unterstützung der Departemente sowie den Unterhalt und Betrieb der zentralen und/oder übergreifenden Informatik- und Kommunikationssystemen. Kanton Solothurn setzt beim Aufbau einer modernen Container-Plattform auf APPUiO. Mit der neuen PaaS unterstützt das AIO die Arbeit der kantonalen Verwaltung und deren Departemente. 
          
  details: |
               <p>Die Umgebung der klassischen IT vom AIO war bis zum Jahr 2017 für die Entwickler sehr komplex, zeitaufwändig, unflexibel und schwer zu koordinieren. Nach intensiver Recherche wurde der Einsatz von OpenShift als neue Plattform gewählt. Das Ziel dabei war es, einen effizienteren Betrieb und eine verbesserte Zusammenarbeit zwischen Entwicklung und Betrieb zu erlangen. Dabei wurde eine OpenShift Plattform von APPUiO aufgebaut. Weiter sammelten die System Engineers Erfahrungen mit der Plattform, damit der Betrieb einwandfrei funktioniert. Dies beinhaltet eine Integration ins Monitoring, Alerting und ein funktionierendes Backup.</p>
               <p>Aus dem vielfältigen Angebot von APPUiO entschied sich das Amt für Informatik und Organisation des Kanton Solothurn für die APPUiO <a href="https://appuio.ch/unmanaged.html">"Self Managed"</a>-Lösung: Eine Container Plattform im eigenen Rechenzentrum, optimal integriert in die eigene Infrastruktur.</p>
               <p>Von dem Architektur Workshop, wobei gemeinsam die Architektur der Plattform definiert wurde, bis hin zum Deployment und Konfiguration des Clusters wurde das AIO von unseren Experten unterstützt. Das Setup wurde gemeinsam umgesetzt, wodurch bereits das Know-How der Engineers des Kanton Solothurns aufgebaut werden konnte. Im Anschluss des Cluster Aufbaus profitierte das AIO vom OpenShift 3rd Level Support Angebot unserer Experten. Die Supportleistungen beziehen sich auf die Analyse und Lösung technischer Problemstellungen ihrer OpenShift Plattform. Zudem kann das AIO das Supportteam bei fachlichen und technischen Fragestellungen oder bei Cluster Upgrades konsultieren. Der Vorteil für das AIO sind die kompetenten Kenntnisse des Supportteams sowie die präferierten Reaktionszeiten. Dank dem 3rd Level Support konnte ein reibungsloser Betrieb von Beginn an ermöglicht werden.</p>

- day: 20
  month: Apr
  title: "Free Upgrade: Higher performance on APPUiO Public"
  subtitle: |
            <img src="/images/blogposts/faster_is_better.png" alt="faster is better"/>
            Fantastic news for all APPUiO Public Shared users: we recently have successfully upgraded our APPUiO Public infrastructure to a whole new level. All APPUiO Public Shared Nodes and Storage Nodes were upgraded to the new Plus flavors on <a href="https://www.cloudscale.ch/de/">cloudscale.ch</a>. This means that you will now profit automatically from increased speed and performance while paying the same price. Some APPUiO customers reported to us a performance increase of around 15% compared to the old infrastructure. 
            
  details: |
             <p>The new Plus flavors are high performance cloud servers on the newest available hardware platform and the underlying physical computing power is not overcommitted. We hope that you are as happy with this upgrade as we are and would love to hear about your experience.</p>
             <p><b>APPUiO Public on <a href="https://www.cloudscale.ch/de/">cloudscale.ch</a></b></p>
             <p><a href="https://www.cloudscale.ch/de/">cloudscale.ch</a> is a APPUiO infrastructure partner since the beginning of APPUiO. Thanks to their brand new AMD-based hardware platform, customers can benefit from high performance environments. This way, the computing power they need is guaranteed to be readily available at any time. This offer is made possible by the use of leading-edge hardware. <a href="https://www.cloudscale.ch/de/">cloudscale.ch</a> is one of the very first IaaS providers to employ compute nodes with the recently launched AMD EPYC "Rome" processors, which feature up to 64 physical cores per socket.</p>
             <p>You can find more information on the <a href="https://www.cloudscale.ch/en/news/2019/11/19/even-more-power-thanks-to-plus-flavor">cloudscale.ch blog</a>.</p>

- day: 25
  month: Mar
  title: "Coronavirus: APPUiO 90 Tage kostenlos"
  subtitle: |
            <img src="/images/blogposts/Voucher_Corona.png" alt="Voucher APPUiO Public 4.3"/>
            Wir erleben gerade noch nie dagewesene Zeiten aufgrund des Coronavirus. Die COVID-19-Pandemie hat erhebliche Auswirkungen auf die Gesundheit der Menschen, unseren Alltag wie auch auf Unternehmen und die Wirtschaft. Angesichts dieser besonderen und immer grösser werdenden Herausforderungen, die wir alle momentan meistern müssen, möchten wir von APPUiO ebenfalls einen Beitrag leisten.
          
  details: |
             <p>Deshalb bieten wir dir als "Soforthilfe" ein APPUiO Public auf <a href="https://www.cloudscale.ch/de/">cloudscale.ch</a> mit 1100 mC CPU, 2.0 GiB Memory für volle 90 Tage kostenlos an, was einem Wert von CHF 300.- entspricht.</p>
             <p>Geh einfach auf <a href="https://register.appuio.ch/">https://register.appuio.ch/</a>, gib deine E-Mail-Adresse und den folgenden Voucher-Code ein: <b>APPUIO-COVID19</b></p>
             <p>Beeil dich, es sind maximal 100 Codes verfügbar und die Aktion gilt 1x pro Benutzer bzw. Firma.</p>
             <p>Liebe Grüsse und trage Sorge zu dir</p>
             <p>dein APPUiO-Team.</p>

- day: 18
  month: Mar
  title: "Neu: Techlab auf OpenShift 4.3"
  subtitle: |
            <img src="/images/blogposts/techlab_auf_openshift_4.3.png" alt="techlab auf OpenShift 4.3"/>
            Vor einiger Zeit hat Red Hat die OpenShift Version 4.3 auf den Markt gebracht. Diese Version hat eine gewisse Reife und kann mit gutem Gewissen auch für produktiven Workload verwendet werden. Aus diesem Grund bieten wir neue Techlabs an!
          
  details: |
             <p>Die #39 Durchführung unseres gratis APPUiO Techlabs wird auf Basis von OpenShift 4.3 durchgeführt. Dabei zeigen wir dir die Unterschiede zu der Version 3 und geben unsere Erfahrungen sowie Tipps und Tricks weiter. Du machst erste Schritte auf einer OpenShift 4.3 Plattform, deployst Applikationen und skalierst diese ganz einfach. Weiter haben wir ein Operator Lab erarbeitet, wo du erste Gehversuche mit dem neuen Operator Framework machen kannst.</p>
             <p>Melde dich wie gewohnt über unsere <a href="https://appuio.ch/techlabs.html">Webseite</a> an.</p>
             <p>Falls du Fragen zur Migration von OpenShift 3.11 auf 4.3 hast, helfen wir dir gerne weiter oder schätzen wir gemeinsam den Aufwand einer solchen Migration. Melde dich dafür ganz einfach mit einer <a href="mailto:hello@appuio.ch">Mail</a>.</p>
             <p>Wenn du dich bereits ein wenig über OpenShift 4 informieren willst, kannst du <a href="https://appuio.ch/blog.html#OpenShift%204">diesen Blogpost</a> lesen.</p>
             <p><b>Aus aktuellen Umständen werden wir die kommende Durchführung am 26. März 2020 Remote abhalten. Wenn du dich für das Techlab anmeldest, erhältst du einen Link für die Techlab Remote Session.</b></p>
             <p>Dies wird für alle Beteiligten eine interessante Erfahrung und wir sind gespannt auf diese neue Herausforderung.</p>
             <p>Bleibt alle gesund und "häbet Sorg"!</p>
- day: 30
  month: Jan
  title: "RedHat OpenShift 4.2 – Installations Pitfalls, Networkingking und Storage"
  subtitle: |
            <img src="/images/blogposts/OpenShift_4.2.png" alt="OpenShift 4.2"/>
            <br>
            <a href="https://www.puzzle.ch/de/home">Puzzle ITC</a>, einer der Gründerfirmen von APPUiO, hat eine Woche genutzt, um ihr Wissen rund um OpenShift 4.2 zu vertiefen. In der sogenannten  <a href="https://www.puzzle.ch/de/blog/articles/2020/01/15/mid-week">/mid Week</a> erzielten die Members spannende Erkenntnisse bei der Installation, Networking und Storage.</a>
  details: |
             <p>Der Blog ist aufgeteilt in drei Themen:</p>
             <p><b>1. Installations-Pitfalls:</b> In der /mid Week haben wir OpenShift 4.2 sowohl auf einem VMware vSphere Cluster wie auch bei AWS, GCP und Azure installiert. Wir berichten über die Probleme, die dabei aufgetaucht sind.</p>
             <p><b>2. Networking:</b> Je nach Cloud Plattform gibt es logischerweise Unterschiede (z.B. Load Balancer). Wir haben aber auch Unterschiede zwischen OpenShift 3.11 und 4.2 festgestellt.</p>
             <p><b>3. Storage:</b> Jeder Cloud Provider bietet diverse Typen von Storage zur Integration in OpenShift an. Wir zeigen euch, was es für Möglichkeiten gibt.</p>
             <b><u>1. Installation Pitfalls</u></b>
             <p><img src="/images/blogposts/Pitfalls.jpg" alt="Pitfalls"/></p>
             <p>Wenn du in diesem Blog nach einer Anleitung suchst, wie OpenShift 4.2 installiert wird, bist du leider falsch. Für die Installationen haben auch wir die offiziellen <a href="https://docs.openshift.com/container-platform/4.2/welcome/index.html">Anleitungen von RedHat</a> verwendet.</p>
             <p>Vorneweg: Die Installation wird mit OpenShift Version 4.2 deutlich einfacher und schneller als mit 3.11. Generell - egal für welche Zielplattform - haben wir Folgendes festgestellt:</p>
             <li>Kleinere Umgebungen als 3 Master / 3 Node (Standardvorgabe) sollten nicht gewählt werden. Es wird sehr langsam oder die Installation schlägt teilweise sogar fehl. </li>
             <li>Für den OpenShift Installer wird ein <em>install-config.yaml</em> File erstellt. Dies sollte vor Beginn der Installation gesichert werden, da der Installer dieses anschliessend löscht.</li>
             <li>Weiter sollten auch alle Terraform Output Files gesichert werden, damit später der Cluster einfach gelöscht werden kann. Achtung, beim Löschen des Cluster erfolgt keine zusätzliche Bestätigung!</li>
             <li>Je nach Plattform haben wir unterschiedliche Grössen der Standard-VM festgestellt.</li>
             <li>Wenn <a href="https://docs.openshift.com/container-platform/4.2/installing/installing_aws/installing-aws-customizations.html#ssh-agent-using_install-customizations-cloud">während der Installation</a> kein SSH-Keyfile angegeben wurde, kann anschliessend nicht auf die VM's per SSH zugegriffen werden.</li>
             <p>Die Installation eines Clusters dauert je nach Plattform unterschiedlich lang:</p>
             <img src="/images/blogposts/Installationsdauer.png" alt="Installationsdauer"/>
             <p><b>VMware vSphere</b></p>
             <p>Einige Bemerkungen zur VMware vSphere Installation:</p>
             <li>Die Dokumentation zur Installation war sehr gut und wir konnten dieser Schritt für Schritt folgen.</li>
             <li>Während der (ersten) Installation mussten wir feststellen, dass Reverse DNS Einträge zwingend notwendig sind. Die Installation war blockiert und wir mussten von neuem beginnen.</li>
             <li>Kleine Fehler in den Ignition (JSON) Files führen zu Fehler, die leider sehr schwer zu finden sind, da keine sinnvolle Fehlermeldung vorhanden ist. So hat uns z.B. ein fehlendes Komma etwa eine Stunde Zeit gekostet. Ignition Files können <a href="https://coreos.com/validate/">hier</a> validiert werden.</li>
             <li>Für die Installation muss ein Load Balancer (z.B. HAproxy) erstellt werden. Siehe auch unten im Teil zu Networking.</li>
             <li>Infrastructur MachineSets für vSphere sind noch nicht implementiert. Daher ist die Installation auf VMware vSphere auch eine <a href="https://blog.openshift.com/openshift-4-install-experience/">User Provisioned Infrastructure (UPI)</a> Installation.</li>
             <p><b>GCP</b></p>
             <p>Damit die Installation auf GCP funktioniert, müssen die folgenden APIs aktiviert sein:</p>
             <li>Identity and Access Management(IAM)</li>
             <li>Cloud Resource Manager API</li>
             <p>Weiter muss die Disksize Limit von 500GB auf 750 GB erh&ouml;ht werden (640GB benutzt nach der Installation). Das Definieren im <em>install-config.yaml</em> File des OpenShift Installer funktioniert leider nicht:</p>
             <pre class="western">
             platform:
                gcp:
                   rootVolume:
                   iops: 4000
                   size: 50
                   type: io1
                type: n1-standard-4</pre>
             <p><b>Azure</b></p>
             <p>Einige Bemerkungen zur Installation auf Azure:</p>
             <li>Free Tier Subscription reicht nicht aus für eine OpenShift Installation.</li>
             <li>Es müssen Anpassungen an den default Azure Account Limits gemacht werden.</li>
             <li>Zürich befindet sich z.Z. nicht unter den supported Azure Regions.</li>
             <li>Die Dokumentation ist falsch bzgl. <em>Azure account limits & Creating a service principal</em>.</li>
             <p><b>AWS</b></p>
             <p>Die Installation auf AWS war am einfachsten. Das liegt wohl daran, dass bereits Openshift 4.0 darauf ausgelegt war.</p>
             <b><u>2. Networking</u></b>
             <p><img src="/images/blogposts/networking.png" alt="networking"/></p>
             <p><b>Load Balancing</b></p>
             <p>Für eine RedHat OpenShift 4.2 Installation werden zwei Load Balancer vor dem Cluster benötigt:</p>
             <li><b>API Load Balancer:</b> Für eine Hochverfügbarkeit der Kubernetes-API (welche auf dem Master läuft), müssen alle API Calls an diese Master Nodes verteilt werden.</li>
             <p>Auf den drei Cloud Provider konnten wir dafür jeweils den Load Balancer Service des Providers verwenden. Dieser wird mit dem OpenShift Installer automatisch konfiguriert. Auf VMware vSphere mussten wir dafür selber einen Load Balancer konfigurieren. Wir haben dafür eine CentOS VM mit HAProxy verwendet. Für die hohe Verfügbarkeit kann z.B. keepalived verwendet werden.</p>
             <li><b>Client Access Load Balancer:</b> Für den Zugriff auf den Applikation Workload wird ein Load Balancer benötigt, der die Ingress Controller weiterleitet.</li>
             <p>Für den Client Access Load Balancer kann auf die Cloud Provider Integration von Kubernetes zurückgegriffen werden. Damit werden mit Hilfe eines <a href="https://kubernetes.io/docs/concepts/services-networking/service/#
             lancer">Kubernetes Services vom Typ Load Balancer</a> automatisch ein Load Balancer auf der entsprechenden Cloud Plattform provisioniert.</p>
             <p>Bei der on-premise Installation mit VMware vSphere muss der Load Balancer selber implementiert werden, welcher den Netzwork Traffic auf die Ingress Controller weiterleitet. Das automatische Erstellen des Load Balancers via Kubernetes Service funktioniert hier leider nicht.</p>
             <p><b>Egress Traffic & NetworkPolicy</b></p>
             <li><b>NetworkPolicy:</b>Die Kubernetes v1 NetworkPolicy Features sind in OpenShift 4.2 verfügbar</li>
             <li><b>Egress IP:</b> Identisch zu OpenShift 3.11. <a href="https://docs.openshift.com/container-platform/4.2/networking/openshift-sdn/assigning-egress-ips.html">(Referenz)</a></li>
             <li><b>EngressNetworkPolicy</b> wir auf OpenShift 4.2 nicht unterstützt </li>
             <li><b>EgressRouter</b> wird auf OpenShift 4.2 nicht unterstützt </li>
             <b><u>3. Storage</u></b>
             <p><img src="/images/blogposts/storage.jpg" alt="storage"/></p>
             <p>Abschliessend schauen wir uns noch die diversen Storage Integrationen für OpenShift 4.2 an. Wir teilen Storage in drei Kategorien ein: Block Storage, File Storage und Object Storage.</p>
             <p><b>Black Storage</b></p>
             <p>Erfreulicherweise hatten wir mit keinem Provider (onpremise wie auch Cloud) Probleme. Nach der Installation gemäss Anleitung konnten wir Block Storage von allen Cloud Providern beziehen. Alle Infos dazu sind in der entsprechenden Dokumentation von RedHat zu finden.</p>
             <li><a href="https://docs.openshift.com/container-platform/4.2/storage/persistent-storage/persistent-storage-gce.html">GCP</a></li>
             <li><a href="https://docs.openshift.com/container-platform/4.2/storage/persistent-storage/persistent-storage-azure.html">Azure</a></li>
             <li><a href="https://docs.openshift.com/container-platform/4.2/storage/persistent-storage/persistent-storage-aws.html">AWS</a></li>
             <li><a href="https://docs.openshift.com/container-platform/4.2/storage/persistent-storage/persistent-storage-vsphere.html">vSphere</a></li>
             <p><b>File Storage</b></p>
             <p>Als File Storage bezeichnen wir solchen, der insbesondere shared bezogen werden kann <a href=https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes">(ReadWriteMany - RWX)</a>.</p>
             <p><b>AWS</b></p>
             <p>Auf AWS steht uns <a href="https://aws.amazon.com/efs/">EWS</a> zur Verfügung, dabei haben wir jedoch Folgendes festgestellt:</p>
             <li>Auf EFS sind alle Volumes nur Subfolder des Root Volume.</li>
             <li>Quotas können nicht forciert werden.</li>
             <li>Keine Usage Metrics</li>
             <li><em>size</em> in einem PVC wird nicht berücksichtigt.</li>
             <li>RedHat sagt zu EFS: <em>"Elastic File System is a Technology Preview feature only.[...]"</em> <a href="https://docs.openshift.com/container-platform/4.2/storage/persistent-storage/persistent-storage-efs.html">Openshift doc on EFS</a></li>
             <li>upstream efs-provisioner: <a href="https://github.com/kubernetes-incubator/external-storage/tree/master/aws/efs">detailed doc & code</a></li>
             <p>Weiter kann auch Netapp Trident verwendet werden. In unserer /mid Week haben wir dies jedoch nicht angeschaut (auch nicht auf den anderen Cloud Provider Plattformen). Dafür wird ein AWS Account mit konfiguriertem NetApp CVS (1TB / 100$ / Monat) benötigt. Infos dazu in der <a href="https://netapp-trident.readthedocs.io/en/stable-v19.07/kubernetes/operations/tasks/backends/cvs_aws.html">Netapp Trident Dokumentation</a>.</p>
             <p><b>Azure</b></p>
             <p>Microsoft bietet mit Azure File die Möglichkeit, dynamisch File Storage zu beziehen. Die folgenden Features werden dabei aber nicht supported.</p>
             <li>Symlinks</li>
             <li>Hard links</li>
             <li>Extended attributes</li>
             <li>Sparse files</li>
             <li>Named pipes</li>
             <p>Alle Informationen dazu sind in der <a href="https://docs.openshift.com/container-platform/4.2/storage/dynamic-provisioning.html#azure-disk-definition_dynamic-provisioning">RedHat OpenShift Dokumentation</a> zu finden. Auch auf Azure kann <a href="https://netapp-trident.readthedocs.io/en/stable-v19.07/kubernetes/operations/tasks/backends/anf.html">Netapp Trident</a> verwendet werden.</p>
             <p><b>GCP</b></p>
             <p>Auf GCP stehen <a href="https://cloud.google.com/solutions/filers-on-compute-engine">mehrere Möglichkeite</a>n zur Verfügung.</p>
             <p>Für <a href="https://cloud.google.com/community/tutorials/gke-filestore-dynamic-provisioning">Cloud File Store kann der nfs-client-provisioner</a> verwendet weren. Auch hier können Quotas nicht forciert werden. Weiter gibt es einen nicht offiziell supporteten <a href="https://github.com/kubernetes-sigs/gcp-filestore-csi-driver">CSI Treiber</a>, den wir aber nicht wirklich zum Laufen gebracht haben.</p>
             <p>Weiter kann auch hier NetApp Cloud Volumes mit Trident verwendet werden. Wir haben hierzu aber keine Dokumentation gefunden. Dies sollte aber ähnlich wie bei <a href="https://netapp-trident.readthedocs.io/en/stable-v19.04/kubernetes/operations/tasks/backends/cvs_aws.html">AWS</a> seine. Weitere Infos dazu sind <a href="https://cloud.google.com/solutions/filers-on-compute-engine#netapp">hier</a> zu finden.</p>
             <p>Eine weitere Möglichkeit ist die Verwendung von <a href="https://github.com/Elastifile/elastifile-provisioner">Elastifile</a> oder <a href="https://github.com/quobyte/quobyte-csi">Quoabyte</a>. Diese müssen aber alle lizenziert werden. Elastifile ist nur für einen eingeschränkten Kundenkreis verfügbar. Quoabyte sieht zur Zeit noch nicht wirklich Enterprise-like aus.</p>
             <p><b>VMware vSphere</b></p>
             <p>In einer on-premise VMware vSphere Umgebung muss einen File Storage Service selbst aufgebaut werden (z.B. mit <a href="https://www.openshift.com/products/container-storage/">RedHat Contrainer Storage</a> basierend auf <a href="https://rook.io/">rook.io</a>).</p>
             <p><b>Object Storage</b></p>
             <p>Auch Object Storage wird von den drei Cloud Provider angeboten. Dieser wird aber in der Regeln nicht als PV in einen Pod gemounted, sondern direkt aus einer Applikation bezogen. Der Vollständigkeit halber hier eine Auflistung der Object Storage Services.</p>
             <li>GCP mit <a href="https://cloud.google.com/storage/">Google Cloud Storage</a></li>
             <li>AWS mit <a href="https://aws.amazon.com/s3/">S3</a></li>
             <li>Azure mit <a href="https://azure.microsoft.com/en-us/services/storage/">Azure Object Storage</a></li>
             <p>In einer on-premise VMware vSphere Umgebung muss ein Object Storage Service selbst aufgebaut werden.</p>
